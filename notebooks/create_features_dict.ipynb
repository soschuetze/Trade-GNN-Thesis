{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Feature Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import sys\n",
    "sys.path.append('/Users/sinclaireschuetze/Documents/GitHub/Trade-GNN-Thesis/src')\n",
    "from utils.CreateFeatures import CreateFeatures\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Econometric Feature Creation\n",
    "This creates the standard networks with the initial node features, including centrality and centrality within each product group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "\n",
    "#GDP data goes up to 2018 -- trange up to 2019 spans up to 2018\n",
    "for year in trange(1962, 2019):\n",
    "    trade = CreateFeatures(year = year)\n",
    "    trade.prepare_econ_features()\n",
    "    trade.prepare_network_features()\n",
    "    #trade.combine_normalize_features()\n",
    "    trade.combine_features()\n",
    "    \n",
    "    data_dict[year] = trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"../feature_dicts/mis_normÃŸ.pkl\", \"wb\") as f:\n",
    "#    pkl.dump(data_dict, f)\n",
    "\n",
    "with open(\"../feature_dicts/mis_norm.pkl\", \"rb\") as f:\n",
    "    data_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to keep track of the DataFrame with the most rows\n",
    "max_rows = 0\n",
    "df_with_max_rows = None\n",
    "\n",
    "# Iterate over the dictionary\n",
    "for key, df in data_dict.items():\n",
    "    # If this DataFrame has more rows than the current maximum, update the maximum and the DataFrame\n",
    "    if len(df.combined_features) > max_rows:\n",
    "        max_rows = len(df.combined_features)\n",
    "        df_with_max_rows = df.combined_features\n",
    "        max_year = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the variance of each column\n",
    "numeric_columns = df_with_max_rows.drop(['country_code'], axis=1)\n",
    "variances = numeric_columns.var()\n",
    "\n",
    "# Find columns with variance less than 0.1 (this is the threshold, adjust as needed)\n",
    "columns_to_drop = variances[variances < 0.1].index\n",
    "filtered_df = df_with_max_rows.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dictionary\n",
    "for key, df in data_dict.items():\n",
    "    df.combined_features = df.combined_features.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One method of feature selection included MIS to remove highly correlated features. These were chosen by regressing the features on GDP and selecting the top 2 percent of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = filtered_df.drop(['country_code','current_gdp_growth'], axis = 1)\n",
    "Y_train = filtered_df['current_gdp_growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "mutual_info = mutual_info_regression(X_train, Y_train)\n",
    "\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X_train.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "\n",
    "selected_top_columns = SelectPercentile(mutual_info_regression, percentile=2)\n",
    "selected_top_columns.fit(X_train, Y_train)\n",
    "selected_top_columns.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns[selected_top_columns.get_support()]\n",
    "X_train = X_train[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = list(columns)\n",
    "column_list.append('current_gdp_growth')\n",
    "column_list.append('country_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in data_dict.items():\n",
    "    df.combined_features = df.combined_features[column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_all_zeros = []\n",
    "for key, df in data_dict.items():\n",
    "    zero_columns = [col for col in df.combined_features.columns if (df.combined_features[col] == 0).all()]\n",
    "\n",
    "    # Iterate over list1\n",
    "    for item in zero_columns:\n",
    "        # If the item is not in list2, add it\n",
    "        if item not in columns_all_zeros:\n",
    "            columns_all_zeros.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in data_dict.items():\n",
    "    df.combined_features = df.combined_features.drop(columns_all_zeros, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_columns = [\"IT.MLT.MAIN.P2\",\"NE.CON.PRVT.KD.ZG\",\"NE.CON.TOTL.KD.ZG\",\"NV.IND.TOTL.KD.ZG\",\"NV.SRV.TOTL.KD.ZG\",\"NY.GDP.MKTP.KD.ZG\",\"NY.GDP.PCAP.KD.ZG\",\"NY.GNP.MKTP.KD.ZG\",\"NY.GNP.PCAP.KD.ZG\",\"SP.ADO.TFRT\",\"SP.POP.2024.FE.5Y\",\"SP.POP.2024.MA.5Y\",\"SP.POP.6569.FE.5Y\",\"SP.POP.6569.MA.5Y\",\"SP.POP.65UP.MA.ZS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_norm = data_dict\n",
    "for i in data_dict:\n",
    "    year = i\n",
    "    year_dict = data_dict[year].combined_features\n",
    "    mis_norm[year].combined_features = year_dict[mis_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../feature_dicts/mis_norm.pkl\", \"wb\") as f:\n",
    "    pkl.dump(mis_norm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method of feature selection as a way of understanding the true predictiveness of MIS features was just selecting random features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = filtered_df.drop(['country_code','current_gdp_growth'], axis = 1).iloc[:,1:-23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_columns = X_train.sample(n=15, axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_columns = ['GC.XPN.TOTL.CN', 'DC.DAC.DNKL.CD', 'ST.INT.DPRT', 'SP.POP.6064.FE.5Y',\n",
    "       'SL.IND.EMPL.MA.ZS', 'DT.NFL.PRVT.CD', 'SE.XPD.CSEC.ZS',\n",
    "       'SP.URB.TOTL.IN.ZS', 'NY.GNP.MKTP.PP.KD', 'DC.DAC.POLL.CD',\n",
    "       'TX.VAL.MRCH.R5.ZS', 'SE.PRM.OENR.FE.ZS', 'NE.CON.GOVT.CN',\n",
    "       'SL.TLF.BASC.ZS', 'EN.ATM.PM25.MC.M3', 'country_code', 'current_gdp_growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dictionary\n",
    "for key, df in data_dict.items():\n",
    "\n",
    "    # Combine the lists\n",
    "    all_cols = ['country_code','current_gdp_growth'] + random_columns.tolist()\n",
    "\n",
    "    # Select the columns from the dataframe\n",
    "    df.combined_features = df.combined_features[all_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../feature_dicts/random_features_dict.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../feature_dicts/feature_dict_logged.pkl\", \"rb\") as f:\n",
    "    data_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_not_norm = data_dict\n",
    "for i in enumerate(data_dict):\n",
    "    year = i[1]\n",
    "    year_dict = data_dict[year].combined_features\n",
    "    random_not_norm[year].combined_features = year_dict[random_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../feature_dicts/random_dict_not_norm.pkl\", \"wb\") as f:\n",
    "    pkl.dump(random_not_norm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were eventually trained on non-normalized data, normalized, and logged data to test which method worked the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_logged = data_dict\n",
    "for year in data_dict:\n",
    "    year_dict = data_dict[year].combined_features\n",
    "    for column in year_dict.columns:\n",
    "        if column != 'country_code':\n",
    "            year_dict[column] = np.log(year_dict[column])\n",
    "    data_dict_logged[year].combined_features = year_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in data_dict_logged:\n",
    "    year_dict = data_dict_logged[year].combined_features\n",
    "    year_dict.replace([np.inf, -np.inf, np.nan], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../feature_dicts/feature_dict_logged.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict_logged, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../feature_dicts/feature_dict_logged.pkl\", \"rb\") as f:\n",
    "    data_dict_logged = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../feature_dicts/mis_features_not_norm.pkl\", \"rb\") as f:\n",
    "    original_mis = pkl.load(f)\n",
    "\n",
    "mis_columns = original_mis[1962].combined_features.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_logged = data_dict\n",
    "for year in data_dict:\n",
    "    year_dict = data_dict[year].combined_features\n",
    "    filtered_dict = year_dict[mis_columns]\n",
    "\n",
    "    for column in filtered_dict.columns:\n",
    "        if column != 'country_code':\n",
    "            filtered_dict[column] = np.log(filtered_dict[column])\n",
    "            \n",
    "    filtered_dict.replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
    "    mis_logged[year].combined_features = filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../feature_dicts/random_logged.pkl\", \"wb\") as f:\n",
    "    pkl.dump(mis_logged, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
